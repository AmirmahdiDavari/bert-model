# from transformers import pipeline
#
# sentiment_pipeline = pipeline("text-classification", model="HooshvareLab/bert-fa-base-uncased-sentiment")
#
#
# def analyze_sentiment(text: str) -> str:
#     result = sentiment_pipeline(text)
#     return result[0]["label"].lower()  # Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ "positive"ØŒ "neutral" ÛŒØ§ "negative" Ø¨Ø§Ø´Ø¯
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load ParsBERT model and tokenizer directly
tokenizer = AutoTokenizer.from_pretrained("HooshvareLab/bert-fa-base-uncased-sentiment-digikala")
model = AutoModelForSequenceClassification.from_pretrained("HooshvareLab/bert-fa-base-uncased-sentiment-digikala")

# Sentiment labels
labels = ["Ù…Ù†ÙÛŒ", "Ø®Ù†Ø«ÛŒ", "Ù…Ø«Ø¨Øª"]


async def analyze_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)

    # Ensure that the model does not track gradients
    with torch.no_grad():
        outputs = model(**inputs)

    # Get softmax probabilities
    scores = outputs.logits.softmax(dim=-1).tolist()[0]
    sentiment = labels[scores.index(max(scores))]  # Get the highest score label

    return sentiment, scores


# # Example Test
# text =  "Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„  Ø®ÙˆØ¨  Ø§Ø³Øª  "
# sentiment, scores = analyze_sentiment(text)
#
# print(f"ğŸ”¹ Ù…ØªÙ†: {text}")
# print(f"ğŸ“Œ Ø§Ø­Ø³Ø§Ø³Ø§Øª: {sentiment}")
# print(f"ğŸ“Š Ø§Ù…ØªÛŒØ§Ø²Ø§Øª: {scores}")
